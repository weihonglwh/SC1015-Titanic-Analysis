{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion of the Titanic Analysis**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our findings and machine learning models, we dedude that both Support Vector Machine (SVM) and Random Forest yields similar results with SVM being slightly better.\n",
    "\n",
    "We also saw that upscaling data reduces FNR to create a better model. Furthermore, we also saw that hyperparameter tuning with `GridSearch` is able to enhance our models, especically for SVM, to the point that it became the best model out of the 3.\n",
    "\n",
    "As we achieved quite a high accuracy for our test data, we are **84.8%** confident that the survivability can be predicted with the following predictors: `Fare`, `Parch`, `Family_Size`, `Sex`, `Pclass`, `Embarked`, `Alone` with the model achieved with SVM. From EDA and the decision tree we see that `Fare` and `Sex` is a very important factor and is highly correlated with `Survived` as those that pay a higher fare is more likely to survive and females has a much more likely chance of survival.\n",
    "\n",
    "Despite already attempting multiple strategies to improve our model such as feature engineering, upscaling and multiple different algorithms (Decision Tree, Random Forest and SVM), we acknowledge that the model we have derived from SVM may still have some room for improvements.\n",
    "\n",
    "Firstly, we have only done 1 model per algorithm, even for the model we chose as optimal, which is the SVM. We acknowledge that we can further improve our model by using what is known as ensemble methods. This refers to combining several base models in order to produce one optimal predictive model. For example, we can adopt bagging ensemble, where we train multiple SVM models on different subsets of the training data to combine and produce one optimal model. Alternatively, we can also adopt boosting ensemble, which refers to training multiple models sequentially with each subsequent model being trained to correct the errors of the previous one.\n",
    "\n",
    "Secondly, we have yet to explore all the algorithms available in machine learning as there is a possibility for another algorithm to produce a better model. For example, we have yet to explore neural network which could potentially yield better results.\n",
    "\n",
    "Thirdly, the model is built off a dataset that can be argued as a smaller dataset as good models will require more data to ensure accuracy. As such, if we were to have had a larger dataset, it could possibly lead to an improvement in our model. \n",
    "\n",
    "With this new insights, we believe that these findings can be used in future maritime disaster aid and prediction to maximise the amount of survivors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
